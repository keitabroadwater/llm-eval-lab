# llm-eval-lab
A web sandbox for hands-on learning of LLM and RAG Evaluation

## Interactive LLM & RAG Evaluation Lab

### Why This Matters – Importance of evaluation (MMLU, Ragas, LLM-as-a-judge concepts)

### Key Features – LLM evaluation playground, RAG quality inspection, visual feedback

### Tech Stack – Next.js, FastAPI/Flask, GPT-4, Ragas

Installation:
bash
Copy code
cd frontend && npm install
cd ../backend && pip install -r requirements.txt

### Running the App:

```bash
# Start frontend
cd frontend
npm run dev

# Start backend
cd backend
uvicorn app.main:app --reload
```

### Example Usage – Screenshots or gifs (when ready)

### Evaluation Concepts Explained – Link to docs/ for in-depth evaluation knowledge